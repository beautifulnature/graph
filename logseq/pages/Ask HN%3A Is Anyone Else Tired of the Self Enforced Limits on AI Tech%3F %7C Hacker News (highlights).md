title:: Ask HN: Is Anyone Else Tired of the Self Enforced Limits on AI Tech? | Hacker News (highlights)
author:: [[news.ycombinator.com]]
full-title:: "Ask HN: Is Anyone Else Tired of the Self Enforced Limits on AI Tech? | Hacker News"
category:: #articles
url:: https://news.ycombinator.com/item?id=33306168

- Highlights first synced by [[Readwise]] [[Feb 20th, 2023]]
	- ML-tech from the past century seems to work just fine for killing each other (have a look at Ukraine). I would be rather more concerned about the foe having better batteries at this point.
	- Now you can, but 120 years ago the British Empire ruled the waves with no reason to think battleships or cavalry would ever be obsolete.
	  The machine gun and trench warfare forced the development of the tank.
	  Once aircraft became military useful, battleships were rapidly vulnerable to aircraft and hence aircraft carriers.
	  I can imagine replacing naval mines with normally-quiescent remote-triggered torpedoes that are scattered on the seafloor a decade in advance.
	  How effective are troops against 3D printed drones designed to mimic animals (including birds), but which have a short-range firearm and some computer vision? Or engineered mosquitoes with the bare minimum of remote control, perhaps similar to the "cyborg cockroach" kits that have been on sale for about 9 years now? (Or just weaponise those 'roaches…)
	  What happens if you can predict what a command officer will say, use an AI to fake a their voice before they've spoken, and interfere with the communications to give misleading orders in the heat of combat? Doesn't even need to be a big change to the orders to alter the outcome.
	  (Obviously everything I've thought of in 5 minutes, the actual military will have categorised into "haha no" and "let's wargame this scenario"; I assume mostly the former).
	- There is a move large companies do where after innovating they pull the ladder up behind them by trying to drag regulators into the space. Regulation establishes a moat and allows them to cruise on that innovation until enough external pressure builds up that the dam breaks (people innovating in countries without that regulation for example).
	  I'm not quite sure what the solution is to this by the way. I don't think the answer is no regulation, but how to improve the quality of regulation.
	- What you're missing is that there are many people who think these things are illegal because "ew that's gross" and they also elect politicians who agree with them.
	  The United States has barely moved past the issue of homosexuality even though it harms no one, it is perhaps the most straightforward modern example of people trying to ban it due to personal & traditional disgust. Although there is a general majority approval for it, that doesn't carry to the electoral level where it remains a contentious partisan issue. But you think the ethics of CP & pedophilia will be discussed and legislated rationally?
	- That would likely accelerate the fall of society as we know it. I can’t think of a stronger financial incentive to go underground, or simply pack up and leave the country.
	  Before the recent AI boom in the US, China was known to have better opportunities for AI researchers. Hugo de Garis and Ben Goertzel both went over to China for that reason some time ago. Interestingly, De Garis predicted that a world war would eventually start over the issue of AI prohibition.
	- Regulation by which only massive players can abide is effectively killing any small or not well funded business.
	  We have civil law. If a company harms you, you can sue. No need to create regulation to make markets less competitive.
	- I recently saw a presentation from someone trying to build a predictive model for violent incidents in mental healthcare settings. They took steps to prevent the model considering race because this could potentially lead to less favorable treatment for some groups.
	  The model was unable to give any useful predictions. I don't know if it would perform better without the deliberate limitations, but I do know that healthcare staff are making their own judgements in it's absence.
	- Once the cat is out of the bag, the problem exists. Worrying about how long exactly it takes for $irresponsible_person to make it slightly worse by reducing the barrier to access even further is, in my opinion, missing the point.
	  There are many examples of this.